# Predictive Analysis: Spam Email Classification
By: Made Rahano Satryani Widhi

| | Deskripsi |
| ----------- | ----------- |
| Dataset | [Spam Email Classification Dataset](https://www.kaggle.com/datasets/purusinghvi/email-spam-classification-dataset/data) |
| Masalah | Permasalahan email spam merupakan fenomena yang meluas di lingkungan digital, mengganggu kegiatan sehari-hari pengguna internet dengan serangan pesan-pesan tidak diinginkan yang berisi penawaran, promosi, atau bahkan ancaman keamanan. Dengan volume spam yang terus meningkat, pengguna sering kali harus membuang waktu dan sumber daya untuk mengelola kotak masuk yang terbebani, sementara risiko terhadap privasi dan keamanan data pun semakin besar. Deteksi spam menjadi tantangan penting dalam menjaga keamanan komunikasi online, dan pengembangan model yang cerdas dan efektif sangat diperlukan untuk mengidentifikasi dan memfilter pesan-pesan tersebut dengan akurasi yang tinggi.<br><br>*Dataset Spam Email Classification* merupakan dataset gabungan yang terdiri dari 83.446 email yang diberi label sebagai spam atau bukan-spam. Dataset ini dibentuk dengan menggabungkan *Corpus Spam Publik TREC 2007* dan Kumpulan Data *Enron-Spam*. Dalam lingkungan nyata, peningkatan volume dan keragaman spam email telah menjadi tantangan besar dalam mengelola kotak masuk email, mengakibatkan gangguan produktivitas dan risiko keamanan informasi yang meningkat. Oleh karena itu, tujuan dari proyek ini adalah mengembangkan model machine learning yang dapat membedakan antara email spam dan non-spam dengan tingkat akurasi yang tinggi. Penyelesaian masalah ini memiliki dampak yang signifikan dalam memperkuat keamanan email, meningkatkan efisiensi komunikasi online, dan memberikan wawasan berharga dalam pengelolaan spam serta pengembangan algoritma deteksi yang lebih canggih. |
| Solusi machine learning | Solusi *machine learning* yang telah dibuat bertujuan untuk melakukan klasifikasi email apakah termasuk dalam kategori spam atau bukan. Dengan menggunakan teknik-teknik klasifikasi dan pengolahan bahasa alami, model ini mampu mempelajari pola-pola yang terdapat pada email-email spam dan email-email non-spam untuk mengidentifikasi dan memisahkan keduanya dengan akurasi tinggi. Dengan demikian, solusi ini dapat membantu pengguna untuk mengelola kotak masuk mereka dengan lebih efisien, mengurangi gangguan dari pesan-pesan spam, dan meningkatkan keamanan serta produktivitas dalam aktivitas komunikasi online. |
| Metode pengolahan | - Proses *Data Ingestion* dilakukan melalui komponen *CsvExampleGen* dari TFX *(TensorFlow Extended)*. Pada tahap ini, data diambil dari sumber (yang merupakan direktori *DATA_ROOT* yaitu *'data'*) dan dibagi menjadi dua bagian utama: *"train"* dan *"eval"*. Setiap bagian dibagi menggunakan hashing dengan masing-masing 8 dan 2 bucket untuk train dan eval.<br>- Proses *Data Validation* dilakukan melalui tiga tahap utama yaitu *Summary Statistic*, *Data Schema*, dan *Identify Anomaly on Dataset* untuk memastikan kualitasnya sebelum digunakan dalam proses *Machine Learning*. Tahap pertama adalah *Summary Statistic*, tahap pertama ini melibatkan pengumpulan statistik ringkasan dari dataset menggunakan komponen *StatisticsGen*. Ini membantu untuk mendapatkan pemahaman yang lebih baik tentang distribusi data, nilai-nilai rata-rata, dan informasi statistik lainnya yang relevan. Setelah itu, statistik yang dihasilkan ditampilkan untuk analisis lebih lanjut. Tahap kedua adalah *Data Schema*, tahap kedua ini melibatkan pembangunan skema data menggunakan komponen *SchemaGen*. Skema ini digunakan untuk menentukan struktur yang diharapkan dari dataset, termasuk tipe data dan batasan lainnya. Skema yang dihasilkan kemudian ditampilkan untuk pemeriksaan lebih lanjut. Terakhir, *Identify Anomaly on Dataset* adalah mengidentifikasi anomali dalam dataset menggunakan komponen *ExampleValidator*. Ini membandingkan statistik dataset dengan skema yang telah ditentukan untuk mendeteksi ketidaksesuaian atau anomali yang mungkin ada.<br>- Proses *Data Preprocessing* dilakukan menggunakan T*ensorFlow Transform* (TFT) untuk mempersiapkan fitur-fitur input menjadi fitur-fitur yang telah diproses atau *"transformed"*. Fungsi *preprocessing_fn* menerima input dalam bentuk peta dari kunci fitur ke fitur mentah, dan mengembalikan output dalam bentuk peta dari kunci fitur ke fitur yang telah diproses. Dalam kode tersebut, fitur teks ("text") diubah menjadi huruf kecil menggunakan fungsi tf.strings.lower, untuk konsistensi dalam pemrosesan teks. Selain itu, label ("label") diubah menjadi tipe data integer menggunakan fungsi tf.cast. Proses ini membantu dalam mempersiapkan data untuk pelatihan model, sehingga memungkinkan model untuk belajar dengan lebih baik dari fitur-fitur yang telah diproses dengan benar.<br>- Proses *Model Development* melibatkan beberapa tahap penting dalam membangun dan melatih model klasifikasi *spam email*. Pertama, terdapat fungsi input_fn yang bertanggung jawab untuk membangun dataset yang akan digunakan untuk pelatihan dan evaluasi model. Dataset tersebut diproses menggunakan *TensorFlow Transform* (TFT) untuk menghasilkan fitur-fitur yang telah diproses. Selanjutnya, dilakukan pembangunan arsitektur model menggunakan *TensorFlow Keras*, dengan lapisan-lapisan seperti *TextVectorization*, *Embedding*, *LSTM*, dan *Dense*. Model ini dikompilasi dengan fungsi *loss* dan *optimizer* yang sesuai untuk klasifikasi biner. Selama pelatihan, digunakan *callback* seperti *TensorBoard*, *EarlyStopping*, dan *ModelCheckpoint* untuk pemantauan dan manajemen pembelajaran. Setelah pelatihan selesai, model disimpan dalam format TensorFlow untuk digunakan dalam proses penyajian selanjutnya. Selain itu, dilakukan visualisasi arsitektur model menggunakan plot_model. Semua tahap ini terintegrasi dalam sebuah fungsi run_fn yang mengelola seluruh proses pembangunan dan pelatihan model dengan menggunakan data yang telah diproses sebelumnya.<br>- Proses *Model Analysis & Validation* dilakukan untuk mengevaluasi dan memvalidasi model klasifikasi *spam email* yang telah dilatih sebelumnya. Tahap pertama melibatkan *Resolver*, yang bertanggung jawab untuk menentukan model terbaru yang telah disetujui untuk digunakan. Selanjutnya, konfigurasi evaluasi (eval_config) disiapkan dengan menetapkan spesifikasi model, spesifikasi pemotongan, dan metrik yang akan dievaluasi. Evaluator kemudian digunakan untuk mengevaluasi model yang dilatih sebelumnya dengan menggunakan data yang telah diproses sebelumnya, bersama dengan model dasar yang dipilih oleh *Resolver*. Hasil evaluasi kemudian divisualisasikan menggunakan *TensorFlow Model Analysis* (TFMA), termasuk metrik-metrik evaluasi seperti *Binary Accuracy* dan indikator keseimbangan yang ditampilkan dalam widget. Selain itu, hasil evaluasi juga dicetak untuk analisis lebih lanjut. Terakhir, model yang telah dievaluasi dan divalidasi dengan baik akan dipublikasikan menggunakan komponen *Pusher* ke destinasi yang telah ditentukan, sehingga siap digunakan dalam proses penyajian lebih lanjut. Semua tahapan ini terintegrasi dalam alur kerja TFX, yang memfasilitasi analisis, validasi, dan publikasi model dengan efisien dan andal. |
| Arsitektur model | Model yang digunakan adalah sebuah model *machine learning* untuk klasifikasi teks, yang dibangun menggunakan *TensorFlow*. Pertama-tama, teks dimasukkan melalui lapisan *TextVectorization*, yang bertugas untuk mengonversi teks menjadi representasi numerik dengan menghapus tanda baca dan mengubah ke huruf kecil, serta membatasi jumlah kata unik *(VOCAB_SIZE)* dan panjang urutan *(SEQUENCE_LENGTH)* dari teks yang diolah. Selanjutnya, lapisan *Embedding* digunakan untuk memetakan kata-kata dalam teks menjadi vektor-vektor ruang bersama dengan dimensi tertentu *(embedding_dim)*. Kemudian, lapisan *Bidirectional LSTM* digunakan untuk memproses urutan teks secara kontekstual dari kedua arah, sehingga memungkinkan model untuk memahami konteks yang lebih baik. Setelah itu, beberapa lapisan *Dense* dengan fungsi aktivasi *ReLU* digunakan untuk memproses fitur-fitur hasil dari *LSTM*. Terakhir, lapisan *Dropout* diterapkan untuk mencegah *overfitting* dengan mengabaikan sebagian unit secara acak selama pelatihan. Model menghasilkan output dalam bentuk probabilitas menggunakan lapisan *Dense* dengan fungsi aktivasi *sigmoid*, yang mengindikasikan apakah teks yang diberikan termasuk dalam kategori spam atau bukan. Model dikompilasi dengan menggunakan fungsi kerugian *binary crossentropy* dan *optimizer Adam* dengan laju pembelajaran 0.01. Metrik evaluasi yang digunakan adalah *binary accuracy*. Model ini memiliki arsitektur yang cukup kompleks dan dapat memberikan klasifikasi teks dengan akurasi yang baik. |
| Metrik evaluasi | Metrik evaluasi yang digunakan untuk mengevaluasi performa model meliputi beberapa metrik yang relevan dalam konteks klasifikasi biner. Pertama, metrik *"ExampleCount"* digunakan untuk menghitung jumlah contoh yang dievaluasi oleh model. Selanjutnya, metrik "AUC" *(Area Under the ROC Curve)* digunakan untuk mengukur seberapa baik model memisahkan kelas positif dan negatif dengan mempertimbangkan semua kemungkinan ambang batas. Selain itu, metrik *"BinaryAccuracy"* digunakan untuk mengukur akurasi prediksi model terhadap kelas-kelas biner. Pada konfigurasi metrik ini, telah ditetapkan threshold untuk BinaryAccuracy, di mana model dianggap berhasil jika akurasi biner yang dicapai lebih besar dari 0.5 dan mengalami peningkatan minimal sebesar 0.0001 untuk dinyatakan sebagai perbaikan. Metrik-metrik ini memberikan gambaran komprehensif tentang performa model dalam mengklasifikasikan data dan membantu menilai sejauh mana model tersebut memenuhi tujuan-tujuan evaluasi yang ditetapkan. |
| Performa model | Performa model telah dievaluasi menggunakan beberapa metrik yang relevan dalam konteks klasifikasi biner. Hasil evaluasi menunjukkan bahwa model yang telah dibuat memiliki tingkat akurasi biner sebesar 98.61%, yang menandakan bahwa model mampu mengklasifikasikan data dengan sangat baik. Selain itu, nilai AUC *(Area Under the ROC Curve)* yang mencapai 99.61% juga menunjukkan bahwa model memiliki kemampuan yang sangat baik dalam memisahkan antara kelas positif dan negatif. Dengan demikian, hasil evaluasi ini mengindikasikan bahwa model yang telah dibuat memiliki kinerja yang sangat baik dalam melakukan klasifikasi email spam dan non-spam. Total contoh yang dievaluasi oleh model sebanyak 16.530. |
| Opsi deployment | Model ini di-deploy menggunakan Dockerfile yang dikonfigurasi untuk meng-host model *TensorFlow* menggunakan *TensorFlow Serving*. Dockerfile ini memuat model yang akan disajikan ke dalam container Docker bersama dengan konfigurasi yang diperlukan, seperti variabel *ENV* untuk port komunikasi, nama model, dan konfigurasi monitoring menggunakan Prometheus. Setelah Dockerfile dikonfigurasi, model tersebut di-hosting menggunakan layanan *Railway*, yang menyediakan infrastruktur handal untuk menjalankan kontainer Docker dengan mudah dan andal. Ini adalah pendekatan efisien dan dapat diandalkan untuk mendeploy model dengan konfigurasi deployment yang diatur melalui Dockerfile dan hosting yang dikelola dengan *Railway* |
| Web app | [se-model](https://spam-email-project-production.up.railway.app/v1/models/se-model/metadata)|
| Monitoring | Monitoring yang dilakukan terhadap model serving menggunakan ekspresi ":tensorflow:core:saved_model:read:api" menghasilkan nilai konstan satu. Ini menunjukkan bahwa model tersebut sedang beroperasi secara konsisten dan memberikan output yang diharapkan dalam setiap panggilan API. Nilai konstan ini menunjukkan bahwa tidak ada variabilitas yang signifikan dalam respons model, yang dapat dianggap sebagai tanda positif dalam ketersediaan dan keandalan model serving. Namun, perlu diingat bahwa ini hanya satu aspek dari kinerja model, dan monitoring yang komprehensif perlu meliputi berbagai aspek seperti kecepatan respons, penggunaan sumber daya, dan akurasi prediksi. |
